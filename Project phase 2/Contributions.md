# StudyBuddy Contribution Document (Phase 2)

## Vivek Reddy Bhimavarapu
* [cite_start]Designed and wrote the the Quiz&Flashcard schema [cite: 2]
* [cite_start]Edited teammates sql’s in the repository primarily in the load folder for seeding and building without errors. [cite: 3]
* [cite_start]Added comments of what I did on the top of the file. [cite: 4]
* [cite_start]Wrote the master script file for creating the study buddy databases that uses everyone's schemas. [cite: 5]
* [cite_start]Changed directories of multiple files in the repository for proper build, and organization [cite: 6]
* [cite_start]Wrote the query optimization analysis for my schema [cite: 7]
* [cite_start]Web scrapped a geeks for geeks quiz to insert into quiz tables. [cite: 8]
* [cite_start]Send the scrapped data of quizzes to Rise to clean it. [cite: 9]
* [cite_start]Recorded the video for my part. [cite: 10]
* [cite_start]Added the database execution output from the video presentation. [cite: 11]

## Rise Akizaki
* [cite_start]Wrote the SQL for the User_Management section. [cite: 13]
* [cite_start]Created all relevant tables (Users, Colleges, Courses, Majors). [cite: 14]
* [cite_start]Tested functionality of the SQL by using test queries (indexing, searching, etc). [cite: 15]
* [cite_start]Tested foreign key relationships between all the tables. [cite: 16]
* [cite_start]Created scripts to clean the data for courses, and quizzes. [cite: 17]
* [cite_start]Created new fields to match the table format. [cite: 18]
* [cite_start]Added missing information required for each field. [cite: 19]
* [cite_start]Altered values to match their respective fields. [cite: 20]
* [cite_start]Outlined the process for creating the data cleaning scripts. [cite: 21]
* [cite_start]Created an additional cleaning script for colleges to make the data match the table format. [cite: 22]
* [cite_start]Removed unnecessary fields [cite: 23]
* [cite_start]Inserted scraped data for the courses, and colleges tables. [cite: 24]

## Sarah Kayembe
* [cite_start]Scraped Colleges & Universities [cite: 26]
    * [cite_start]Identified a reliable public source (Wikipedia-accredited institutions). [cite: 27]
    * [cite_start]Extracted institution names, states, and categories. [cite: 28]
    * [cite_start]Cleaned inconsistencies, and removed duplicates [cite: 29]
    * [cite_start]Saved as CSV for import (us_colleges.csv). [cite: 30]
* [cite_start]Scraped List of Majors / Academic Programs [cite: 31]
    * [cite_start]Located major listings from valid sources. [cite: 32]
    * [cite_start]Extracted major names. [cite: 33]
    * [cite_start]Cleaned and standardized capitalization. [cite: 34]
    * [cite_start]Removed duplicates and empty entries. [cite: 35]
* [cite_start]Scraped Courses for USM [cite: 36]
    * [cite_start]Iterated through the paginated course catalog. [cite: 37]
    * [cite_start]Collected course codes, titles, and sources. [cite: 38]
    * [cite_start]Validated course structure. [cite: 39]
    * [cite_start]Exported to CSV. [cite: 40]
* [cite_start]Scraped Study Resources (Learning Materials) [cite: 41]
    * [cite_start]Collected online study resources linked to course topics. [cite: 42]
    * [cite_start]Removed irrelevant results, duplicates, and broken URLs. [cite: 43]
    * [cite_start]Ensured resources had valid titles and source links. [cite: 44]
    * [cite_start]Normalized data and aligned each resource with a course. [cite: 45]
* [cite_start]Attempted Scraping Quizzes & Flashcards [cite: 46]
    * [cite_start]Built a working scraper that collected practice questions and answers. [cite: 47]
    * [cite_start]Ensured schema alignment (Quiz → Question → Answer). [cite: 48]
    * [cite_start]Later removed from final deliverables so teammates could handle it. [cite: 49]
* [cite_start]General Cleaning [cite: 50]
    * [cite_start]Normalized text (trimmed spaces, removed HTML noise, fixed unicode). [cite: 51]
    * [cite_start]Dropped duplicates using Pandas. [cite: 52]
    * [cite_start]Ensured all mandatory fields were present. [cite: 53]
    * [cite_start]Verified foreign key references existed before inserting. [cite: 54]
* [cite_start]Validation Rules Implemented [cite: 55]
    * [cite_start]Checked regex formatting for titles (e.g., monthly challenge titles). [cite: 56]
    * [cite_start]Ensured date rules: end_date > start_date focus sessions had valid time ranges [cite: 57]
    * [cite_start]Verified numeric ranges for: [cite: 58]
        * [cite_start]durations [cite: 59]
        * [cite_start]streak values [cite: 60]
        * [cite_start]reward thresholds [cite: 61]
* [cite_start]Ensured Foreign Key Integrity [cite: 62]
    * [cite_start]Built lookup dictionaries (e.g., user_id → stats, topic_id → names). [cite: 63]
    * [cite_start]Checked that every row matched an existing FK entry BEFORE insertion. [cite: 64]
    * [cite_start]Logged anomalies (none appeared after cleaning). [cite: 65]
* [cite_start]Inserted All Scraped Data Into MySQL to test and perform [cite: 66]
    * [cite_start]Inserted colleges, majors, courses, and resources. [cite: 67]
    * [cite_start]Inserted mood levels, item types, task categories, and topic types. [cite: 68]
    * [cite_start]Inserted all focus items with categories and rarity levels. [cite: 69]
    * [cite_start]Inserted daily focus logs with: [cite: 70]
        * [cite_start]sessions [cite: 71]
        * [cite_start]total focus time [cite: 72]
        * [cite_start]topics [cite: 73]
        * [cite_start]JSON fields (validated) [cite: 74]
        * [cite_start]always-valid item_earned_id (tiered reward system) [cite: 75]
* [cite_start]Created Additional Gamification Tables With Synthetic Data [cite: 76]
    * [cite_start]userfocusitems [cite: 77]
    * [cite_start]usercitylayout [cite: 78]
    * [cite_start]monthlychallengesuserchallengeprogress [cite: 79]
    * [cite_start]moodtracking [cite: 80]
    * [cite_start]leaderboardstats [cite: 81]
    * [cite_start]studyStats (fully computed using SQL + Python) [cite: 82]
* [cite_start]Built Synthetic Data for Testing [cite: 83]
    * [cite_start]Generated: [cite: 84]
        * [cite_start]100+ daily focus logs [cite: 85]
        * [cite_start]100 monthly challenges [cite: 86]
        * [cite_start]mood logs [cite: 87]
        * [cite_start]challenge progress [cite: 88]
        * [cite_start]leaderboard entries [cite: 89]
    * [cite_start]Ensured no NULLs in required fields. [cite: 90]
    * [cite_start]Verified JSON validity before insertion. [cite: 91]
* [cite_start]Completely wrote the SQL script for the study_management page and normalized it. [cite: 92]
* [cite_start]Broke ENUМs into reference tables: [cite: 93]
    * [cite_start]topic_types [cite: 94]
    * [cite_start]task_categories [cite: 95]
    * [cite_start]item_types [cite: 96]
    * [cite_start]mood_levels [cite: 97]
* [cite_start]Query Optimization & Indexing [cite: 98]
    * [cite_start]idx_task_user_status_due [cite: 99]
    * [cite_start]idx_task_course_status [cite: 100]
    * [cite_start]idx_timer_host_start [cite: 101]
    * [cite_start]idx_timer_host_end_duration [cite: 102]
    * [cite_start]idx_participant_user [cite: 103]
    * [cite_start]uq_user_date (unique composite index) [cite: 104]
    * [cite_start]idx_focus_type [cite: 105]
    * [cite_start]idx_challenge_reward [cite: 106]
    * [cite_start]idx_progress_challenge [cite: 107]
    * [cite_start]idx_city_user [cite: 108]
    * [cite_start]idx_stats_topic [cite: 109]
    * [cite_start]idx_leader_user [cite: 110]
* [cite_start]Ran Query Performance Analysis [cite: 111]
* [cite_start]Compared Performance With & Without Indexes [cite: 112]
* [cite_start]Stored Procedures & Backend Logic (Study Management System): I implemented several key stored procedures that support the Study Management system’s core functionality, including: [cite: 113]
    * [cite_start]Procedures for adding, updating, and retrieving tasks. [cite: 114]
    * [cite_start]Procedures for inserting timer sessions and calculating session durations. [cite: 115]
    * [cite_start]Procedures for updating user study statistics (total minutes, streaks, averages). [cite: 116]
    * [cite_start]Leaderboard update procedures and challenge-progress procedures. [cite: 117]
* [cite_start]Additional Deliverables [cite: 118]
    * [cite_start]Saved all data as CSV for reproducibility. [cite: 119]
    * [cite_start]Produced a video demonstration of the scraped data and code. [cite: 120]

## Jacob Craig
* [cite_start]Designed and implemented all tables related to the Study Group & Collaboration section [cite: 122]
* [cite_start]Created Test data for the Study_Groups & Collaboration section [cite: 123]
* [cite_start]Built a Python data cleaning script that takes a CSV file for course resources and: [cite: 124]
    * [cite_start]Removes duplicates [cite: 125]
    * [cite_start]Cleans up whitespace and inconsistent patterns [cite: 126]
    * [cite_start]Normalizes title formats [cite: 127]
    * [cite_start]Outputs a CSV compatible with MySQL [cite: 128]
    * [cite_start]Generates SQL Code for the resource table [cite: 129]
* [cite_start]Looking to improve upon this by eventually automatically inserting from the program into the database [cite: 130]
* [cite_start]Created a full query workload with procedures and created indexes for the Study Groups & Collaboration section of the database [cite: 131]
* [cite_start]Created automated triggers, procedures, and constraints for the Study Groups & Collaboration section of the database [cite: 132]
* [cite_start]Created a group_summary table to help with optimization [cite: 133]
* [cite_start]Designed three automated triggers to: [cite: 134]
    * [cite_start]Increment member count on join [cite: 135]
    * [cite_start]Decrement on removal [cite: 136]
    * [cite_start]Update the latest session on new session creation [cite: 137]
* [cite_start]Recorded working Resource Cleaner Program and working procedures [cite: 138]
